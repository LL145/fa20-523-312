{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxicologyASV.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIfvfOFfg4yBvL+j6bageg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cybertraining-dsc/fa20-523-312/blob/master/toxicologyASV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuTP0XZphrQG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw4eY8-thzwQ"
      },
      "source": [
        "Commencement of first attempt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnnnUXgOh6Tm"
      },
      "source": [
        "#  Attempt 1 ~ Assignment 7\n",
        "#  Name: Saptarshi Sinha\n",
        "#  Date: 10/16/2020\n",
        "#  ENGR-E 534: Aquatic Toxicity Analysis with the aid of Autonomous Surface Vehicle (ASV)\n",
        "#  Description: Implementation of a basic pythonic framework for analyzing the USGS and EPA databases\n",
        "#  IMPORTANT INSTRUCTION: The following code assumes all applicable packages/libraries are pre-installed.\n",
        "#  IMPORTANT INSTRUCTION: It also assumes the data file (provided in the submission) is in the appropriate pythonic path.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "\n",
        "def main():\n",
        "    # loading the USGS database as a panda data-frame\n",
        "    # loading the USGS database as a panda data-frame\n",
        "    ## columns = [\"sample\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"Class\"]\n",
        "    ## df = pd.read_csv('filename.csv', na_values = '?', names = columns) # replace \"filename.csv\" to that of the downloaded file's name\n",
        "    \n",
        "    # imputing missing values of column A5 (let's say) with the mean of non-NaN values of the same column \n",
        "    ## mean_A5 = df[\"A5\"].mean()\n",
        "    ## filled_df = df.fillna(mean_A5)\n",
        "    \n",
        "    # slicing for the attributes (which are A2 through A10)\n",
        "    ## attributes = [\"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\"]\n",
        "    \n",
        "    # creating a temporary dataframe that will only deal with the attributes in question\n",
        "    ## temp_df = filled_df[attributes]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLWBReQ_jSjk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}